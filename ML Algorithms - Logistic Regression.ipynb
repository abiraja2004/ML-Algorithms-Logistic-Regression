{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "- In statistics, the logistic model (or logit model) is a statistical model that is usually taken to apply to a binary dependent variable. \n",
    "- In regression analysis, logistic regression or logit regression is estimating the parameters of a logistic model. \n",
    " [More](https://en.wikipedia.org/wiki/Logistic_regression)\n",
    "- Logistic regression is used to describe data and to explain the relationship between one dependent binary or dichotomous variable and one or more nominal, ordinal, interval or ratio-level independent variables.\n",
    "- In logistic regression, the dependent variable is binary or dichotomous, i.e. it only contains data coded as 1 (TRUE, success, pregnant, etc.) or 0 (FALSE, failure, non-pregnant, etc.).\n",
    "- Logistic regression generates the coefficients (and its standard errors and significance levels) of a formula to predict a logit transformation of the probability of presence of the characteristic of interest:\n",
    "![](./LR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For more details refer my blog [here](https://www.vaishalilambe.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see how it works with random data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  1.0\n",
      "Logistic Regression:  1.0\n",
      "Logistic Regression:  0.5\n",
      "Logistic Regression:  0.5\n",
      "Logistic Regression:  0.514\n",
      "Logistic Regression:  0.514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "clf1 = LogisticRegression(penalty='l2',C=1e9) # very weak l2-regularization\n",
    "y = np.zeros(1000)\n",
    "y[500:] = 1.\n",
    "\n",
    "x1 = np.linspace(0,1,2000)\n",
    "x1[1000:] = np.linspace(0,1,1000)\n",
    "x1[1500:] = np.linspace(0,1,500)\n",
    "x1 = x1.reshape((1000,2))\n",
    "\n",
    "x2 = np.ones((2000, 1))\n",
    "x2[500:] = np.full((1500,1), -3)\n",
    "x2[1000:] = np.full((1000,1), -1)\n",
    "x2 = x2.reshape(1000,2)\n",
    "\n",
    "x3 = np.random.randint(0,100,2000).reshape(1000,2)\n",
    "\n",
    "\n",
    "for dataset in [x1,x2,x3]:\n",
    "    for i in range(2):\n",
    "            print (\"Logistic Regression: \", round(clf1.fit(dataset,y).score(dataset,y),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using theano.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model:\n",
      "[ 1.64047844e+00 -4.81994517e-01  4.41019536e-01 -5.84647005e-01\n",
      " -2.49986601e-01  5.93661962e-01 -1.71276791e-01 -4.67607235e-01\n",
      " -1.20117477e+00  2.72899812e-01  1.78929510e+00  1.56215834e-01\n",
      " -7.21836171e-01 -4.50860702e-01 -1.74136594e+00 -8.49375650e-01\n",
      "  5.42138486e-01 -6.64274979e-01  9.54770135e-02  1.44837975e-01\n",
      "  5.16730967e-01  1.40393291e+00 -2.84511712e-01  1.19928548e+00\n",
      "  1.22752989e+00 -5.51905090e-01 -1.20545712e+00 -1.42479217e-01\n",
      "  1.32466562e+00  4.88141844e-01 -5.60850523e-01 -7.01778701e-01\n",
      " -3.49610900e-01 -6.42670024e-01  2.22087525e-01  1.38117894e+00\n",
      "  1.07573837e+00 -2.12864112e-02 -9.79670324e-01  1.09031169e+00\n",
      " -1.16767954e-01 -7.26359542e-01 -1.72760543e+00 -9.76469753e-02\n",
      " -3.19967359e-01 -1.28598589e+00 -1.48007168e+00  8.29704000e-01\n",
      "  1.07606429e-01 -6.78366774e-01  6.51192224e-01  1.33917110e-01\n",
      "  1.18655019e+00  5.61706177e-01 -7.39704351e-01  1.04739892e-01\n",
      "  6.85090946e-02  1.14526811e+00 -1.06807233e+00  7.72125122e-01\n",
      "  6.73729667e-01  6.41311649e-02 -6.29392597e-01  2.49554903e-01\n",
      "  3.16507823e-01  1.02289783e+00  7.21983085e-01 -7.38117394e-01\n",
      " -9.47272073e-01 -6.26348517e-01  7.11136008e-01  6.24514885e-01\n",
      "  3.69639693e-01  9.49900491e-01 -7.35985012e-01  2.88107504e-01\n",
      " -1.18054621e-01  1.65594053e+00 -1.08068026e+00 -6.81279601e-01\n",
      " -3.91074714e-01 -1.99565996e-01 -5.45595954e-01  1.17940004e+00\n",
      "  4.64511169e-01 -7.52211703e-01 -5.60336831e-01  1.33464536e-01\n",
      " -9.67053172e-01 -6.17269565e-01 -7.13791217e-01 -2.52356064e+00\n",
      "  5.42810572e-01 -3.67114172e-01 -1.09641666e+00  3.67781029e-01\n",
      " -1.74260323e+00 -7.97057126e-01  2.40476678e+00  1.28872835e+00\n",
      "  1.82899741e+00  2.94789949e-01  1.35351074e+00  2.74101294e+00\n",
      "  3.20218715e+00 -1.20627762e+00  1.76126312e+00 -1.57646485e+00\n",
      "  7.08697308e-01  3.26120189e-01  6.26662409e-01  2.03412242e-02\n",
      "  2.06636643e+00  2.10276054e-01 -1.51083211e+00 -1.72664531e-01\n",
      "  1.27711957e+00  3.05221018e-01 -8.54837093e-01 -1.74839695e+00\n",
      "  7.11953126e-01  1.11011932e+00 -8.23638453e-01 -1.22094820e+00\n",
      " -3.72783139e-01 -1.51022045e+00 -8.63545162e-01  6.81676947e-01\n",
      " -1.05458478e+00 -2.54888277e-01  2.33996476e-01 -4.91531424e-04\n",
      " -1.07802550e+00  9.17260169e-01 -8.24719861e-01  2.10946995e+00\n",
      " -1.40311257e+00 -5.08998701e-01 -2.60017530e-01  6.21853767e-02\n",
      "  6.79103466e-01 -2.29717874e-01 -8.15457209e-01  1.02413902e+00\n",
      "  3.89514016e-01  1.94526631e+00 -3.25687116e-01 -3.59844379e-02\n",
      "  1.03891830e+00  5.14706538e-01  5.66623446e-01 -7.45729646e-01\n",
      " -1.15835497e+00 -3.09200216e-01  1.78076022e+00  2.89450112e-01\n",
      "  3.55814441e-01  2.68720413e-01  1.03700771e+00 -8.45873711e-01\n",
      "  2.69992499e-01  7.90424945e-01  1.10808184e+00  5.21042195e-01\n",
      "  3.78486864e-02  7.29582273e-01 -5.08650091e-01  1.21504239e+00\n",
      "  3.57965764e-01 -6.28978648e-01  3.35630681e-02 -2.22614314e+00\n",
      "  4.85590933e-01  6.12347120e-01  6.41571744e-01 -3.31984905e-01\n",
      "  3.28992448e-01  7.60125804e-01  2.38670550e-01  7.79856474e-02\n",
      " -1.22060516e+00 -8.56878757e-01  1.51684288e+00  1.61405853e+00\n",
      " -5.63161343e-01  1.48399443e+00 -9.60608065e-01 -6.10579333e-01\n",
      " -1.71792247e+00 -6.90681695e-01  6.85935640e-01 -2.67932003e-01\n",
      "  3.01300247e-01 -1.14998185e+00 -8.34109706e-01  1.33127344e+00\n",
      "  1.66991060e+00 -3.36095773e-01 -1.44619378e+00  4.23261948e-01\n",
      " -5.84857879e-01  1.04146618e+00 -9.65985081e-01 -1.18371083e+00\n",
      " -3.46238696e-02  9.94086861e-01 -5.39815567e-01  2.95545900e-01\n",
      "  1.71828738e-01  1.40618655e+00 -4.50948705e-01  4.20901342e-01\n",
      " -2.89871487e-01 -8.72095355e-01  1.03956302e+00  1.24886048e-01\n",
      "  9.08031819e-01  2.87164571e-01 -4.79461495e-01  9.76540630e-01\n",
      "  4.70490348e-01  5.31883162e-01  1.20334224e+00 -1.81444392e+00\n",
      " -4.47647052e-01 -2.20930082e-01  1.25584956e+00 -3.57008680e-01\n",
      "  2.97319347e+00 -7.33647120e-01 -1.71116791e+00  1.31662317e+00\n",
      " -1.85329850e-01  9.13032610e-01  1.77476985e+00 -4.02579318e-02\n",
      " -1.46978505e-01 -8.25204349e-01 -2.12318638e-01  6.79967856e-01\n",
      "  2.74223601e+00  5.74323603e-01 -3.69418235e-01  1.24759741e+00\n",
      " -1.13980318e+00  1.46571921e-01 -4.42351245e-01  5.20917535e-01\n",
      "  2.11280434e-01 -2.22498097e+00 -3.05822212e-01  5.30567467e-01\n",
      " -1.12185699e+00 -1.30886761e+00 -8.46210642e-01  1.13768928e+00\n",
      "  2.35876341e+00  8.15981361e-01 -3.47110350e-01 -6.88822546e-01\n",
      " -2.87834590e-01  5.40523034e-01 -1.37697654e+00  3.23542467e-01\n",
      " -1.64644741e+00 -3.21371766e-01 -9.22140744e-01 -7.43081241e-02\n",
      "  5.18793282e-01 -7.76032440e-01  2.34531303e-01  1.15003212e+00\n",
      " -3.67333527e-01  1.19194080e+00 -1.14219078e+00 -1.45781567e-01\n",
      " -1.17955287e+00  1.55562143e-01  1.41453115e+00  1.90806788e+00\n",
      "  1.62893000e-01 -2.30470564e+00 -2.34541836e-01  1.31279394e+00\n",
      " -5.53377915e-01  6.62236188e-01  5.42218377e-02  5.04362408e-01\n",
      "  1.88425747e-01  9.29185654e-02 -1.41844549e+00  3.49121654e-02\n",
      " -1.44316042e+00  2.30284277e-01  2.83247287e-02  3.22551822e-02\n",
      " -4.17939381e-01  5.96953482e-01  1.34143639e+00  7.27457301e-01\n",
      " -3.58290234e-01  2.28443031e+00  7.17140325e-01  3.51045136e-01\n",
      "  7.75779055e-01 -1.37825464e+00  1.58280936e-01 -9.34003587e-01\n",
      " -2.42484809e+00  6.46291249e-01 -2.86224634e-01 -1.04392190e+00\n",
      "  5.90708544e-01  1.06785457e+00  4.78524897e-01 -1.07320427e+00\n",
      "  8.65314606e-01 -5.32991186e-02 -1.64887960e+00  1.37516928e-01\n",
      "  1.73616391e-01  1.06394732e+00  1.72365020e+00 -4.33545277e-01\n",
      " -8.59785398e-01  9.79192117e-01 -7.33480603e-02 -8.09285818e-01\n",
      " -7.50811243e-01 -8.27862425e-01 -1.07836898e+00 -3.70424888e-01\n",
      " -1.46598757e+00 -9.40969106e-02 -1.02162185e-01  2.03485603e-01\n",
      "  8.68499784e-01 -1.17735439e+00  2.00958370e-01  7.92767243e-01\n",
      " -1.70346650e-01 -5.65085020e-01  2.52908874e-01 -2.10309495e+00\n",
      " -1.67709924e+00  6.04922748e-01 -1.65495934e-01 -1.71220566e+00\n",
      " -1.42365341e+00 -5.10191557e-01  3.50013288e-01 -3.32424796e-01\n",
      "  4.88542645e-02 -1.80353846e+00  1.07048172e+00 -2.64703006e+00\n",
      " -1.15955517e+00  2.11728805e-01 -7.23470707e-01 -9.42902224e-01\n",
      " -8.38605542e-01  7.48327667e-01  6.17742755e-01  2.15923467e-01\n",
      " -2.31919000e+00 -1.81438613e+00 -1.29348526e+00 -3.24969988e+00\n",
      " -5.74386197e-01 -1.00283144e+00  5.56594095e-01  1.26335382e-01\n",
      " -2.21037946e+00 -5.49865323e-02 -1.30049491e+00  5.24901922e-01\n",
      " -1.62575982e+00  2.59656483e-01 -8.57164608e-01  5.81298285e-01\n",
      "  1.53995370e+00  2.59450077e-01 -7.92779948e-01  1.26945103e+00\n",
      " -5.25472000e-01  1.82530095e+00  1.02911544e+00  3.03019873e-02\n",
      " -3.98912928e-01  4.20956706e-01 -2.23028209e-01  5.70947552e-01\n",
      "  2.25993925e+00 -7.20401077e-01  7.87419236e-01 -1.96521738e-01\n",
      " -2.40913162e-01 -1.28157520e-01 -1.13043121e+00  1.92320129e-01\n",
      "  2.18297704e+00  4.09612805e-01 -8.63563281e-01  1.87450289e-01\n",
      " -2.08764772e-02 -1.93131759e-01 -2.11331279e+00 -4.91824547e-01\n",
      " -2.26972342e-01 -1.80207473e+00  8.55872484e-01  1.62098967e+00\n",
      " -4.36537135e-01  2.08759095e-01 -1.47316391e+00  1.73101202e+00\n",
      "  1.29412585e+00  7.04107669e-01 -6.51106636e-01 -2.25927610e+00\n",
      " -1.92439308e+00  3.52197704e-01 -2.55299585e-01 -2.29042003e-01\n",
      " -3.11364329e-01  3.68387270e+00 -3.26588709e-01 -1.66937802e+00\n",
      "  1.15752070e-01  6.10259593e-01 -1.28997376e-01  3.75730451e-01\n",
      "  7.10002038e-01  6.61739112e-01  3.28236143e-01 -2.00570045e-01\n",
      "  6.64374001e-01 -1.53788091e+00 -7.14859158e-01 -1.56007145e-01\n",
      " -6.19572637e-01 -8.40599567e-01 -1.07962116e+00 -1.63154911e+00\n",
      "  2.04846264e-01 -2.44492520e-01  5.75460584e-01 -8.07613467e-01\n",
      "  1.97930810e-01 -3.84991137e-02 -8.90584516e-01 -1.08690479e+00\n",
      " -1.66006912e-01  1.12227993e+00  1.02581988e+00 -1.30812104e+00\n",
      " -1.29784735e+00 -3.72882332e-01  5.45061888e-01 -1.43724018e-01\n",
      " -4.70257965e-01  6.17361792e-01  6.21365941e-01 -8.08172723e-01\n",
      "  2.04999606e+00 -1.20165243e+00 -1.27496258e+00 -4.31924686e-01\n",
      "  1.11166720e+00 -3.75291415e-02 -1.61658779e+00 -6.08285564e-01\n",
      "  1.76219882e-01 -1.30084930e+00  1.38956088e+00  1.97334184e+00\n",
      "  8.37429730e-01  3.22113398e-01 -3.02323176e-01  4.38626445e-01\n",
      "  8.70657797e-01 -7.52924008e-02  2.16121804e+00 -6.98329238e-01\n",
      " -9.63917874e-01 -2.08049090e-01  1.51591428e-01 -1.30865887e+00\n",
      " -2.46695431e+00  4.99239080e-01  8.45822344e-01 -1.98752650e-01\n",
      " -3.09610478e-01 -4.72863874e-01  1.06312107e+00 -8.93059007e-01\n",
      "  8.17681508e-01  3.54432615e-01 -1.67571835e-01 -7.94457899e-01\n",
      " -6.73747831e-01 -1.70070208e+00  5.66128839e-01 -6.05942685e-02\n",
      "  8.45942060e-01 -7.65076628e-02  5.44975718e-01  6.08167556e-02\n",
      "  1.20289864e+00 -1.72604286e+00  2.43596639e-01 -1.39903079e+00\n",
      " -1.57695976e-01  1.88383389e+00  3.26302919e-01  9.33728419e-01\n",
      "  1.40198325e+00 -4.13038918e-01 -4.16467134e-01 -2.92075535e-01\n",
      "  6.59798109e-01 -1.91734094e-01 -9.19578919e-01 -9.72084644e-01\n",
      "  8.45716443e-01 -1.15934110e+00 -1.84891262e-01  3.15545175e+00\n",
      " -2.98703010e+00  6.73360095e-01 -7.01231557e-02 -7.50263588e-01\n",
      " -1.39752220e+00  2.18703077e-01 -7.80628223e-01 -1.34145552e-01\n",
      " -1.39582508e+00  1.94332684e+00 -6.87727769e-01 -6.57479528e-01\n",
      "  6.61033760e-02  1.26655705e-01 -6.03934806e-02 -4.96271493e-02\n",
      "  3.32108636e-01  1.85897622e+00  1.45814112e+00  1.17030871e+00\n",
      " -2.19200094e-01  3.47956958e-01  5.53627890e-01 -1.26790540e+00\n",
      " -4.03745378e-01  6.71590787e-01 -9.14774646e-01 -2.44810529e+00\n",
      "  3.20241025e-01  1.28902638e+00 -1.81353683e+00  1.10772647e+00\n",
      "  5.60598496e-01  1.06436547e+00 -1.17990516e+00  9.81088416e-01\n",
      " -1.21718022e+00 -3.40152179e-01  1.23735608e+00  1.23471180e+00\n",
      "  1.08810549e+00  9.33762964e-01 -1.16855019e+00  9.13074644e-01\n",
      "  1.48249897e+00 -1.38765115e+00  8.27303568e-01 -3.78711161e-01\n",
      " -3.17453308e-01 -8.10382182e-01 -4.65498672e-01 -1.84458381e-01\n",
      " -2.99850838e-01 -8.16453031e-01  8.82009419e-03 -5.46684200e-01\n",
      " -2.96838748e-01  6.84061489e-01 -2.17666381e-01  1.11355900e+00\n",
      "  9.78680554e-01 -6.14474484e-01  6.39758204e-01 -9.21317031e-01\n",
      "  4.17320915e-01  5.00714068e-01  1.76882384e-01 -6.96502889e-01\n",
      " -1.29937465e-01 -2.22666242e-01  1.35760244e+00 -1.13654287e+00\n",
      "  1.41179345e+00 -3.46074977e-01  1.93821904e-01  1.76489055e-01\n",
      " -3.11747663e-01  8.65837377e-01 -1.49070581e-01 -1.53640884e+00\n",
      " -6.68302289e-02 -5.73334055e-03  3.42211880e-01 -1.02742734e+00\n",
      " -5.79310292e-01 -4.52055134e-01  1.21296533e+00  1.26802822e+00\n",
      "  3.64520592e-01 -2.10601326e+00  2.76080458e-01 -1.61084982e+00\n",
      "  1.09756359e+00 -5.40471676e-01 -2.17924138e-01  3.88537358e-01\n",
      " -6.32613751e-02  7.65918815e-01  1.39835644e+00 -1.66904326e-01\n",
      "  2.80102588e-01  1.54676432e+00 -2.98825553e-01 -1.31957644e+00\n",
      "  2.66719668e+00  2.02578566e-01  2.42045234e-01  1.20464971e+00\n",
      "  2.44797001e-01  5.53134096e-01  3.42341255e-02  9.17441564e-01\n",
      " -1.25787563e+00  9.65224736e-01  7.47885739e-01  8.57468288e-01\n",
      "  1.18327297e-01 -5.15323339e-01  4.26429427e-01  9.52985493e-01\n",
      "  4.90133395e-02 -1.52531463e+00 -7.02453784e-01  1.06603687e+00\n",
      "  1.83240004e-01  7.93613968e-01  7.49585571e-01  8.54081198e-01\n",
      "  3.73309514e-01 -4.45904348e-01 -8.87974276e-01  1.53209328e+00\n",
      " -7.69486687e-01  3.02679474e-02  1.16482495e+00  1.43658344e-01\n",
      "  7.93047707e-01  2.01756970e-01 -1.10158510e+00  9.90262524e-01\n",
      "  4.93135219e-01  2.13041557e-01  5.30631561e-01 -3.89976236e-01\n",
      " -9.71621816e-01 -8.79316869e-01 -7.00675848e-01 -9.69743362e-01\n",
      "  5.80993369e-02  2.63186348e-01  1.32103801e+00 -1.34005801e+00\n",
      " -5.88308542e-01 -8.25058227e-01  9.59248062e-01  1.45349975e-01\n",
      "  1.83410630e-01 -3.56635311e-01  1.33890809e+00 -1.14781175e+00\n",
      "  7.61396009e-01 -1.05033896e+00  1.85264635e+00  2.53104701e-01\n",
      " -6.11609602e-01 -3.37639641e-01 -6.64482542e-01 -9.79236137e-01\n",
      "  1.70677481e+00 -2.16708867e+00  8.74610917e-01  1.79503923e-01\n",
      "  1.25936713e-01 -2.96903222e+00 -5.37390042e-01  3.30885885e-01\n",
      " -2.71053031e-01 -8.19841069e-01 -2.22175203e-01  1.19787066e+00\n",
      " -4.68006161e-01 -1.25510334e+00  1.76503620e-01 -1.54473537e-01\n",
      "  6.66395054e-01  2.21252584e+00 -3.20945313e-01  8.62353479e-01\n",
      "  5.82859682e-02  6.08266189e-01 -1.11397962e+00  1.48718733e+00\n",
      " -1.12904020e+00  1.30543627e+00  6.75949355e-01  1.16072614e+00\n",
      " -1.93187149e-01  2.51723870e-01  7.80672719e-01  3.12962322e-01\n",
      " -5.92056031e-01 -1.03835401e+00 -1.30493979e+00  8.39009407e-01\n",
      " -8.72416735e-01  8.48749729e-01 -9.45207873e-01  4.63188549e-01\n",
      "  8.73784526e-01  2.81195536e-01 -5.16429959e-01 -5.25286390e-01\n",
      " -2.31650593e-01  8.25987972e-01 -4.52058061e-01  7.99534905e-01\n",
      "  1.37554539e+00 -3.05835087e-01  4.15910052e-01 -5.76225419e-01\n",
      " -3.83410885e-02  1.09049903e+00  2.18325081e-01  1.73647197e+00\n",
      " -3.01480949e-01 -1.49106331e+00  7.47407500e-01 -5.30023024e-02\n",
      " -2.21049419e+00 -1.06380352e+00 -1.42484422e-02  5.73264024e-01\n",
      " -1.08276813e+00 -9.28293174e-01 -6.28653975e-01 -1.44496056e+00\n",
      " -1.20353722e+00 -6.10694278e-01 -7.38302239e-01  1.57172854e+00\n",
      " -2.14880563e-01  4.25729393e-02  1.91791213e+00 -9.74974465e-02\n",
      " -1.15456892e+00  7.79877920e-01 -7.96363851e-02 -1.09364101e-01\n",
      "  7.61968378e-02  9.39594572e-01  7.52059923e-01  5.56592627e-01\n",
      " -1.77524407e+00 -6.11357729e-01  1.18597950e+00 -3.68800204e-01]\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model:\n",
      "[-0.09173154 -0.10877711  0.10499131 -0.03154551 -0.05508796 -0.05543443\n",
      " -0.11544347 -0.116399   -0.0664053   0.00066984 -0.01223363  0.08652811\n",
      " -0.0041002  -0.10418555 -0.08764236 -0.08475434 -0.20822515 -0.03551689\n",
      " -0.09348714  0.06699744 -0.04290784 -0.08402953 -0.16189063 -0.22224539\n",
      "  0.07785754 -0.0513885  -0.04407324  0.15188824  0.02285953  0.03103061\n",
      "  0.08231723  0.03676593  0.08520006  0.12550805 -0.05877756  0.1903799\n",
      " -0.08389776  0.05029488  0.05814087  0.15653955 -0.13939119 -0.06942138\n",
      " -0.0316577   0.02725184 -0.09316351  0.02288952  0.00160791  0.09480763\n",
      " -0.13019046  0.01822936 -0.13110487 -0.04190126 -0.12689235 -0.05844928\n",
      "  0.04142964 -0.00993344 -0.02400879  0.16849085 -0.15748702  0.00840998\n",
      " -0.0238996   0.00189324 -0.09700619 -0.17366248  0.0888514   0.06713423\n",
      " -0.19261074  0.01733177 -0.0041465   0.11464587 -0.03682766 -0.03184685\n",
      " -0.03400276  0.0024083   0.02641044 -0.0994153  -0.05167606 -0.22234325\n",
      "  0.09798095 -0.1276081  -0.12625977 -0.00370612  0.09371886 -0.03490444\n",
      " -0.00467136  0.00565066 -0.03338416 -0.05452089  0.08285825  0.09209128\n",
      "  0.03062859  0.06022538  0.02504539 -0.10892129 -0.07100136  0.04767281\n",
      "  0.04207579  0.0667151  -0.13051108 -0.1643944  -0.02098386  0.04555483\n",
      " -0.04671379 -0.02201959  0.00596883  0.02511203  0.00800758  0.17940127\n",
      " -0.02099024  0.04766644  0.12602599 -0.02671558 -0.05277086 -0.10450775\n",
      "  0.02152788  0.13151594  0.11366811  0.13998519 -0.02023031 -0.037294\n",
      " -0.13909667  0.04336058 -0.06075434 -0.04247979 -0.01444802  0.08865569\n",
      "  0.10623718 -0.03232778 -0.05864162 -0.10015368 -0.07751288  0.09106486\n",
      "  0.0490061  -0.00218031 -0.0250152  -0.09327345 -0.10029288 -0.15069343\n",
      " -0.03710786  0.08892069 -0.02266603 -0.08878829 -0.03254389 -0.08893572\n",
      " -0.00407951 -0.03957695  0.0375877   0.11471232 -0.04121496 -0.09982065\n",
      "  0.06504531  0.04041728 -0.15832696 -0.11007584  0.07773334 -0.01176053\n",
      " -0.14772953  0.15724262  0.11360978 -0.02901299  0.10784737 -0.01269715\n",
      "  0.00690971 -0.16110879 -0.05324287 -0.1159146   0.12658547  0.07729349\n",
      " -0.02189926 -0.06993389  0.10551546  0.11833847 -0.09440039 -0.01721109\n",
      " -0.02102941  0.20288181  0.03387599  0.13080809  0.11171454 -0.00150795\n",
      " -0.05504568  0.08457509  0.03187324 -0.00768677  0.12229556  0.10844213\n",
      "  0.16181985  0.02057928 -0.10732658 -0.02992523 -0.08609892 -0.0849899\n",
      "  0.16539221 -0.1511071  -0.07128877 -0.13029736 -0.01879259  0.02275026\n",
      "  0.03781518  0.08299664  0.15276078  0.06771637 -0.13653429 -0.13453958\n",
      "  0.02671436 -0.1954288  -0.00116413 -0.00477511 -0.02549588  0.06029813\n",
      "  0.03296832  0.03845616  0.10021995 -0.05514217  0.15060003 -0.23340215\n",
      " -0.17725121  0.00871557  0.03305698  0.09294649 -0.03879573 -0.10733591\n",
      "  0.03380391 -0.19374942 -0.05964839 -0.04423859 -0.04812892  0.08944833\n",
      " -0.10178155 -0.041977    0.0164856  -0.1679325  -0.15750021 -0.03844384\n",
      "  0.04312116 -0.21288335  0.05498473  0.05550308  0.03836237  0.07743251\n",
      "  0.10261109  0.04731004  0.05933641  0.21609181 -0.03989619  0.07863942\n",
      " -0.00657265  0.10005437 -0.02744773 -0.13874533  0.05377965  0.08716637\n",
      " -0.11004626  0.02074898 -0.13999897 -0.07530591 -0.03641911 -0.08980402\n",
      "  0.04031332 -0.0215042  -0.01327258  0.01293799  0.08042245 -0.10609512\n",
      "  0.01541975  0.03964689  0.11984523  0.05033642 -0.07151065 -0.14760634\n",
      " -0.00116167  0.23201485 -0.06599738  0.01133692  0.00271138  0.05829467\n",
      " -0.00966009 -0.13164878 -0.02537278 -0.10283682  0.02700955 -0.03060922\n",
      " -0.1042598  -0.14315375 -0.10308781  0.00563508 -0.10124696  0.01542823\n",
      "  0.0340701  -0.07291368  0.16019727  0.08884868  0.16832923 -0.0192478\n",
      " -0.0879323   0.16010041 -0.07505331  0.09932521 -0.0727048  -0.01664217\n",
      " -0.11205995  0.16134041 -0.01624469 -0.08423707  0.03043374  0.12033369\n",
      "  0.06238743 -0.11439945  0.05339455 -0.09944438 -0.02021286 -0.05660153\n",
      " -0.13735968 -0.06661492  0.0567473  -0.02238045  0.11050799 -0.0180154\n",
      " -0.01407375 -0.0171103   0.10329185  0.07431709 -0.29872382 -0.19598291\n",
      "  0.09740516  0.09191601  0.07444409  0.0877972  -0.06630359  0.12567435\n",
      " -0.0924679  -0.06530459  0.12381295  0.16959467 -0.01689465  0.05652229\n",
      "  0.00723349  0.03637153  0.09860343 -0.04301672 -0.13225216  0.10203895\n",
      " -0.10006465  0.07474442  0.14212754  0.00967849  0.02637312 -0.05523992\n",
      "  0.01711438  0.16550346  0.0515276  -0.00258709  0.12529422 -0.08827864\n",
      "  0.10776423  0.11041743  0.14955166 -0.00107873  0.02814165  0.14493723\n",
      "  0.01098712 -0.05054213  0.02603603 -0.00861097 -0.03001507 -0.0341816\n",
      "  0.00401247 -0.00967904 -0.06477927  0.01682868 -0.13404023  0.02763912\n",
      "  0.06745644 -0.06898415  0.08562272 -0.10798877 -0.14505468 -0.04032719\n",
      "  0.01688214 -0.1671961  -0.0748611  -0.0523617   0.01439191 -0.05291342\n",
      " -0.01319691 -0.0578034  -0.10941809 -0.05591638  0.07822983  0.01617653\n",
      "  0.16386085  0.08596361  0.11556546  0.29543167  0.04245718 -0.12342589\n",
      "  0.03441801 -0.07541096 -0.23122998 -0.14447233  0.1374016  -0.00538705\n",
      " -0.04724592 -0.10548695  0.20444304 -0.0749595  -0.09639233 -0.08989945\n",
      " -0.08768199  0.05467827  0.0402554  -0.11626078  0.09415106  0.0171973\n",
      "  0.07216595 -0.0839655  -0.12161116 -0.08797033 -0.03132262  0.02853902\n",
      " -0.0555494  -0.00045674  0.02385326  0.02958558 -0.0149002   0.09197525\n",
      " -0.06192403  0.07323266  0.07478796 -0.05444892  0.19257937  0.07961823\n",
      "  0.04570507 -0.00298733  0.07326477  0.13933659  0.07942362  0.07043186\n",
      " -0.02446883 -0.1258714  -0.15327393  0.08117734 -0.01396181  0.10986416\n",
      "  0.04746199  0.06122253 -0.00848894 -0.07435768 -0.02460954 -0.04115028\n",
      "  0.0694371  -0.14959771  0.05004957 -0.05054378 -0.18763822 -0.02203397\n",
      " -0.06867533  0.08767843 -0.00837712 -0.01264494  0.07372983  0.04639955\n",
      " -0.06004984  0.04359521 -0.07926587  0.02481819  0.14236328 -0.01692155\n",
      " -0.0399663  -0.13461531 -0.14763593 -0.19260643  0.01826287 -0.18214347\n",
      " -0.00411962  0.13924685 -0.06842673 -0.10222564 -0.06613359  0.10270501\n",
      " -0.09018748  0.11904914 -0.03825087 -0.04530212  0.12268381  0.00405773\n",
      " -0.02273793  0.05662819  0.10983322 -0.15279282  0.02759995  0.0556202\n",
      "  0.06692582 -0.15129112 -0.12646905  0.07711372 -0.10441552  0.17096046\n",
      "  0.1431133  -0.04454941 -0.0200922   0.00151505 -0.08846768  0.11290611\n",
      "  0.20354282 -0.13626747  0.13313868 -0.12807457  0.07176599  0.2667719\n",
      " -0.10921945  0.07246089  0.12036944  0.02656497  0.07181504  0.09955697\n",
      "  0.12033475  0.02773598 -0.20032382 -0.02281945 -0.05733837  0.09737327\n",
      "  0.10131359 -0.01990217  0.10911803 -0.06325056  0.04875817 -0.09512037\n",
      "  0.0182682  -0.04012875 -0.01914426  0.09300534 -0.09522393 -0.00543171\n",
      " -0.12257978 -0.15603152  0.02046622 -0.01665678 -0.09131376 -0.00843244\n",
      "  0.08269779  0.06636599  0.05435447  0.04593374 -0.01249246 -0.02307021\n",
      " -0.05432141 -0.03192409 -0.14533744 -0.15100459 -0.06571479 -0.02894261\n",
      "  0.1380556  -0.03147242 -0.14645661 -0.13959147 -0.05496094 -0.02612447\n",
      " -0.00440193 -0.14154365 -0.12567003  0.00385311  0.14255516  0.11804051\n",
      " -0.09825448  0.16003921 -0.07601935  0.10056312 -0.02044995 -0.03037229\n",
      " -0.01003283 -0.01189952  0.0255323   0.06195911  0.03302612 -0.03576434\n",
      " -0.15645428 -0.00514994  0.03495919  0.05569343 -0.02411493  0.19056646\n",
      " -0.02650694  0.0337295   0.01030826 -0.01036961  0.0199605  -0.22116315\n",
      " -0.08206592  0.12560172 -0.22199228  0.03196093 -0.14482578  0.19375302\n",
      " -0.05475814 -0.08673752 -0.06474331 -0.12635632 -0.0806937  -0.08715891\n",
      " -0.0238466   0.05120711  0.06681571  0.13242836  0.05194232 -0.05539023\n",
      " -0.03253866  0.03617283  0.00570856  0.14370551 -0.08255501  0.14649233\n",
      " -0.04963075 -0.05763897  0.10231021  0.0079611  -0.14458005 -0.08747545\n",
      " -0.05837754  0.03204117 -0.05496616 -0.03554797  0.01633675 -0.032917\n",
      "  0.13737864 -0.12597276 -0.07552694  0.12272788  0.08833834 -0.12839825\n",
      "  0.16950684 -0.07506587 -0.09148264  0.22102033  0.11370283 -0.0916796\n",
      " -0.04319853 -0.05533331 -0.07855319 -0.03410267  0.00800847  0.09404093\n",
      " -0.1064791   0.08912241  0.00225249  0.01444446  0.03770992 -0.0510811\n",
      "  0.1002095  -0.05038901 -0.04430255 -0.10551954 -0.24162656 -0.17394325\n",
      " -0.05969414 -0.01872754  0.02917591  0.2628543  -0.06031639 -0.15342845\n",
      " -0.10222172 -0.0230151  -0.15383443 -0.12899423 -0.01496279 -0.12935287\n",
      "  0.05696569  0.02250226  0.15603796  0.00934741 -0.01791536 -0.07197529\n",
      " -0.03921699 -0.12843512 -0.03712737  0.02432841 -0.06348578  0.14472219\n",
      " -0.00776114 -0.07284193 -0.04108379  0.02661897 -0.06702549 -0.0315603\n",
      " -0.13331347 -0.07429263 -0.1616646   0.01165193 -0.03587773  0.01594667\n",
      " -0.02007238 -0.15032505  0.0406938  -0.12554648  0.226391    0.05934788\n",
      " -0.25281742  0.05930869  0.04792403 -0.0797458  -0.13111575 -0.05568073\n",
      "  0.00235013  0.01056233  0.02317274  0.1243571   0.07001808 -0.15177293\n",
      " -0.08606756  0.07862399 -0.12614175 -0.16948777 -0.00232602  0.04548407\n",
      "  0.14643307  0.05895114  0.07569984 -0.04143081  0.09663354 -0.09823628\n",
      "  0.10020837 -0.09212182  0.050761   -0.08658183  0.07724253  0.09039827\n",
      " -0.04514574 -0.12059559 -0.03449017  0.07830748  0.00739721 -0.00261214\n",
      "  0.08440154 -0.02940878 -0.11774631  0.12614298  0.03564599 -0.06680983\n",
      " -0.12793417 -0.04281712 -0.04404797 -0.12663752 -0.04172923  0.1540261\n",
      " -0.19242216  0.08195819  0.08204895  0.01997258  0.13142913  0.11409224\n",
      " -0.05915414 -0.01500482 -0.01789952 -0.15637488 -0.1235515   0.02531927\n",
      "  0.08165521  0.05553735  0.16500271 -0.10506415 -0.06864522  0.04903413\n",
      "  0.00192635  0.09991831 -0.07454297  0.0156845  -0.10387937  0.01555274\n",
      "  0.13304847  0.01728577  0.0187603  -0.02090434 -0.04190435  0.04879145\n",
      "  0.11548089  0.1015715  -0.0469759   0.04284027 -0.06782077 -0.13577506\n",
      "  0.10978683 -0.20630115  0.06666509 -0.08534739]\n",
      "0.0773647765162771\n",
      "target values for D:\n",
      "[0 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 1 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0\n",
      " 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1\n",
      " 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1\n",
      " 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0]\n",
      "prediction on D:\n",
      "[False False False False False  True False  True False  True  True  True\n",
      " False False  True False False False  True  True False  True False  True\n",
      "  True  True  True  True  True False  True  True  True  True  True False\n",
      "  True  True  True False  True  True  True  True False  True  True False\n",
      "  True  True False False  True  True False False  True  True  True  True\n",
      "  True False False False  True  True  True False False  True False  True\n",
      "  True False False False False False  True False  True  True  True  True\n",
      " False False  True False False  True False False False False  True  True\n",
      " False  True False False  True  True  True  True False  True  True  True\n",
      " False  True False False False False False  True  True False False False\n",
      " False  True  True  True  True False  True False  True  True False False\n",
      " False  True  True  True False  True False False  True False  True False\n",
      "  True False False False False  True  True False  True  True False False\n",
      "  True  True False  True False False False False  True False  True  True\n",
      "  True  True  True False  True False  True  True  True False  True  True\n",
      " False False False  True  True  True  True False  True False  True False\n",
      " False  True  True False False False  True False False  True  True False\n",
      " False  True False  True  True  True  True  True False  True False False\n",
      "  True False False  True False  True  True  True False  True  True  True\n",
      "  True False  True  True False False  True  True  True  True  True  True\n",
      " False  True  True  True False False False  True  True  True  True False\n",
      " False  True  True  True  True  True False False  True False False False\n",
      " False  True False  True  True False False False  True False False  True\n",
      "  True  True  True False False  True  True False False False False False\n",
      " False False False False False False False  True False False  True False\n",
      "  True False False  True False  True  True  True  True  True False False\n",
      "  True False  True  True  True False False False  True  True  True  True\n",
      " False  True False  True False False False False  True False False False\n",
      " False False False False False  True  True  True False False False False\n",
      " False False False  True  True False  True  True False False  True False\n",
      " False  True  True  True  True  True False False False  True False  True\n",
      "  True  True False False False  True  True  True False  True False  True\n",
      " False False False False False False  True False False  True False False\n",
      "  True  True  True False]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "rng = numpy.random\n",
    "\n",
    "N = 400\n",
    "feats = 784\n",
    "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n",
    "training_steps = 10000\n",
    "\n",
    "# Declare Theano symbolic variables\n",
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "w = theano.shared(rng.randn(feats), name=\"w\")\n",
    "b = theano.shared(0., name=\"b\")\n",
    "print(\"Initial model:\")\n",
    "print(w.get_value())\n",
    "print(b.get_value())\n",
    "\n",
    "# Construct Theano expression graph\n",
    "p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))   # Probability that target = 1\n",
    "prediction = p_1 > 0.5                    # The prediction thresholded\n",
    "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss function\n",
    "cost = xent.mean() + 0.01 * (w ** 2).sum()# The cost to minimize\n",
    "gw, gb = T.grad(cost, [w, b])             # Compute the gradient of the cost\n",
    "                                          # (we shall return to this in a\n",
    "                                          # following section of this tutorial)\n",
    "\n",
    "# Compile\n",
    "train = theano.function(\n",
    "          inputs=[x,y],\n",
    "          outputs=[prediction, xent],\n",
    "          updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))\n",
    "predict = theano.function(inputs=[x], outputs=prediction)\n",
    "\n",
    "# Train\n",
    "for i in range(training_steps):\n",
    "    pred, err = train(D[0], D[1])\n",
    "\n",
    "print(\"Final model:\")\n",
    "print(w.get_value())\n",
    "print(b.get_value())\n",
    "print(\"target values for D:\")\n",
    "print(D[1])\n",
    "print(\"prediction on D:\")\n",
    "print(predict(D[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression 3-Class Classifier in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the decision boundary\n",
    "# For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "x_ = np.arange(x_min, x_max, h)\n",
    "y_ = np.arange(y_min, y_max, h)\n",
    "xx, yy = np.meshgrid(x_, y_)\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_to_plotly(cmap, pl_entries):\n",
    "    h = 1.0/(pl_entries-1)\n",
    "    pl_colorscale = []\n",
    "    \n",
    "    for k in range(pl_entries):\n",
    "        C = list(map(np.uint8, np.array(cmap(k*h)[:3])*255))\n",
    "        pl_colorscale.append([k*h, 'rgb'+str((C[0], C[1], C[2]))])\n",
    "        \n",
    "    return pl_colorscale\n",
    "\n",
    "cmap = matplotlib_to_plotly(plt.cm.Paired, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "trace = go.Heatmap(x=x_, y=y_, z=Z,\n",
    "                   colorscale=cmap,\n",
    "                   showscale=False,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trace1 = go.Scatter(x=X[:, 0], y=X[:, 1],\n",
    "                    mode='markers',\n",
    "                    marker=dict(color=X[:, 0],\n",
    "                                colorscale=cmap,\n",
    "                                showscale=False,\n",
    "                                line=dict(color='black', width=1))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(xaxis=dict(title='Sepal length', ticks='',\n",
    "                              showticklabels=False),\n",
    "                   yaxis=dict(title='Sepal width', ticks='',\n",
    "                              showticklabels=False)\n",
    "                  )\n",
    "\n",
    "fig = go.Figure(data=[trace, trace1], layout=layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression for Iris dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "Test  1: 50, 2: 50, 3: 50\n",
      "Train 1: 50, 2: 50, 3: 50\n"
     ]
    }
   ],
   "source": [
    "#Load Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "#Check the shape of data\n",
    "print (X_iris.shape)\n",
    "print (y_iris.shape)\n",
    "\n",
    "#Check if sets balanced\n",
    "print ('Test  1: {}, 2: {}, 3: {}'.format(np.sum(y_iris == 0), np.sum(y_iris == 1), np.sum(y_iris == 2) ) )\n",
    "print ('Train 1: {}, 2: {}, 3: {}'.format(np.sum(y_iris == 0), np.sum(y_iris == 1), np.sum(y_iris == 2) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create separate each feature array\n",
    "a = X_iris[:,0]\n",
    "b = X_iris[:,1]\n",
    "c = X_iris[:,2]\n",
    "d = X_iris[:,3]\n",
    "\n",
    "\n",
    "#Scale X data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform (X_iris,y_iris)\n",
    "X_scaled = scaler.transform (X_iris)\n",
    "\n",
    "\n",
    "#Make modified features sets with squares of each feature\n",
    "X_squares   =  np.vstack (([a**2], [b**2], [c **2], [d**2])).T\n",
    "\n",
    "#Make modified features set with multiplied pairs of each feature\n",
    "X_multi = np.vstack ((a*b, a*c, a*d, b*c, b*d, c*d)).T\n",
    "\n",
    "#Make polynomial transformation n = 10\n",
    "transform = PolynomialFeatures(10)\n",
    "transform.fit_transform(X_iris)\n",
    "X_poly = transform.transform(X_iris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make split for original data\n",
    "(X_tr_o, X_ts_o, y_tr_o, y_ts_o ) = train_test_split(X_iris, y_iris, stratify=y_iris, test_size= 0.3)\n",
    "\n",
    "#Make split for scaled data\n",
    "(X_tr_sc, X_ts_sc, y_tr_sc, y_ts_sc) = train_test_split(X_scaled, y_iris, stratify = y_iris, test_size = 0.30)\n",
    "\n",
    "#Make split of polynomial extended features set\n",
    "(X_tr_p, X_ts_p, y_tr_p, y_ts_p ) = train_test_split(X_poly, y_iris, stratify=y_iris, test_size= 0.3)\n",
    "\n",
    "#Make split of squares of each feature\n",
    "(X_tr_sq, X_ts_sq, y_tr_sq, y_ts_sq ) = train_test_split(X_squares, y_iris, stratify = y_iris, test_size = 0.3)\n",
    "\n",
    "#Make split of  multyplied pairs of each feature\n",
    "(X_tr_m, X_ts_m, y_tr_m, y_ts_m ) = train_test_split(X_multi, y_iris, stratify = y_iris, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create estimator class\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "#Create param grid\n",
    "paramgrid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'penalty': ['l1','l2']}\n",
    "\n",
    "#Create SearchGridCV optimizer\n",
    "optimizer = GridSearchCV(estimator, paramgrid, cv=10)\n",
    "\n",
    "#Fit it for original data\n",
    "optimizer.fit(X_tr_o, y_tr_o)\n",
    "predict = optimizer.best_estimator_.predict(X_ts_o)\n",
    "z_o = accuracy_score(y_ts_o,predict)\n",
    "\n",
    "#Fit it for scaled data\n",
    "optimizer.fit(X_tr_sc, y_tr_sc)\n",
    "predict = optimizer.best_estimator_.predict(X_ts_sc)\n",
    "z_sc = accuracy_score(y_ts_sc,predict)\n",
    "\n",
    "#Fit it for  multiplied and squared features set\n",
    "optimizer.fit(X_tr_p, y_tr_p)\n",
    "predict = optimizer.best_estimator_.predict(X_ts_p)\n",
    "z_p = accuracy_score(y_ts_p,predict)\n",
    "\n",
    "#Fit it for squares only of each feature\n",
    "optimizer.fit(X_tr_sq, y_tr_sq)\n",
    "predict = optimizer.best_estimator_.predict(X_ts_sq)\n",
    "z_sq = accuracy_score(y_ts_sq,predict)\n",
    "\n",
    "#Fit it for multiplaied pairs of features\n",
    "optimizer.fit(X_tr_m, y_tr_m)\n",
    "predict = optimizer.best_estimator_.predict(X_ts_m)\n",
    "z_m = accuracy_score(y_ts_m,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for original: 0.9555555555555556\n",
      "Accuracy score for scaled: 0.9555555555555556\n",
      "Accuracy score for polynomial: 0.9111111111111111\n",
      "Accuracy score for squares: 0.9777777777777777\n",
      "Accuracy score for multi: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy score for original: {}'.format(  z_o) )\n",
    "print ('Accuracy score for scaled: {}'.format (  z_sc) )\n",
    "print ('Accuracy score for polynomial: {}'.format( z_p) )\n",
    "print ('Accuracy score for squares: {}'.format( z_sq) )\n",
    "print ('Accuracy score for multi: {}'.format(  z_m) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, it's looks like polynomial features set give 0.95 accuracy each time, but other sets metrics are different from time to time. Looks, like it's the maximum accuracy possible to achived with Logistic Regression method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Real dataset - US Adult income kaggle competition [Refer](https://www.kaggle.com/johnolafenwa/us-census-data/kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult-test.csv\n",
      "adult-training.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = '../input/adult-training.csv'\n",
    "test_data = '../input/adult-test.csv'\n",
    "columns = ['Age','Workclass','fnlgwt','Education','Education Num','Marital Status',\n",
    "           'Occupation','Relationship','Race','Sex','Capital Gain','Capital Loss',\n",
    "           'Hours/Week','Country','Above/Below 50K']\n",
    "train=pd.read_csv(training_data, names=columns)\n",
    "test=pd.read_csv(test_data, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function for estimating missing values in each columns\n",
    "def missing_value(df):\n",
    "    miss=[]\n",
    "    col_list=df.columns\n",
    "    for i in col_list:\n",
    "        missing=df[i].isnull().sum()\n",
    "        miss.append(missing)\n",
    "        list_of_missing=pd.DataFrame(list(zip(col_list,miss)))\n",
    "    return list_of_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Workclass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fnlgwt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Education</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Education Num</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marital Status</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Relationship</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Race</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Capital Gain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Capital Loss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hours/Week</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0  1\n",
       "0               Age  0\n",
       "1         Workclass  0\n",
       "2            fnlgwt  0\n",
       "3         Education  0\n",
       "4     Education Num  0\n",
       "5    Marital Status  0\n",
       "6        Occupation  0\n",
       "7      Relationship  0\n",
       "8              Race  0\n",
       "9               Sex  0\n",
       "10     Capital Gain  0\n",
       "11     Capital Loss  0\n",
       "12       Hours/Week  0\n",
       "13          Country  0\n",
       "14  Above/Below 50K  0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value(test)\n",
    "missing_value(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Husband           13193\n",
       " Not-in-family      8305\n",
       " Own-child          5068\n",
       " Unmarried          3446\n",
       " Wife               1568\n",
       " Other-relative      981\n",
       "Name: Relationship, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Relationship.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Prof-specialty       2032\n",
       " Exec-managerial      2020\n",
       " Craft-repair         2013\n",
       " Sales                1854\n",
       " Adm-clerical         1841\n",
       " Other-service        1628\n",
       " Machine-op-inspct    1020\n",
       " ?                     966\n",
       " Transport-moving      758\n",
       " Handlers-cleaners     702\n",
       " Tech-support          518\n",
       " Farming-fishing       496\n",
       " Protective-serv       334\n",
       " Priv-house-serv        93\n",
       " Armed-Forces            6\n",
       "Name: Occupation, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Occupation.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16282, 15)\n",
      "(32561, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlgwt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education Num</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours/Week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Above/Below 50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age          Workclass  fnlgwt   Education  Education Num  \\\n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "5   37            Private  284582     Masters             14   \n",
       "\n",
       "        Marital Status          Occupation    Relationship    Race      Sex  \\\n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "5   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
       "\n",
       "   Capital Gain  Capital Loss  Hours/Week         Country Above/Below 50K  \n",
       "1             0             0          13   United-States           <=50K  \n",
       "2             0             0          40   United-States           <=50K  \n",
       "3             0             0          40   United-States           <=50K  \n",
       "4             0             0          40            Cuba           <=50K  \n",
       "5             0             0          40   United-States           <=50K  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(train.shape)\n",
    "\n",
    "\n",
    "# deleted the firt rows of the both dataframes since these are errorneous\n",
    "test.drop(test.index[0]).head()\n",
    "train.drop(train.index[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a swiss knife tool for separating string columns to separate list and numerical to separate list\n",
    "all_data=[train, test]\n",
    "str_list=[]\n",
    "\n",
    "for data in all_data:\n",
    "    for colname, colvalue in data.iteritems(): \n",
    "        if type(colvalue[1]) == str:\n",
    "            str_list.append(colname) \n",
    "num_list = data.columns.difference(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                0\n",
      "Workclass          1\n",
      "fnlgwt             1\n",
      "Education          1\n",
      "Education Num      1\n",
      "Marital Status     1\n",
      "Occupation         1\n",
      "Relationship       1\n",
      "Race               1\n",
      "Sex                1\n",
      "Capital Gain       1\n",
      "Capital Loss       1\n",
      "Hours/Week         1\n",
      "Country            1\n",
      "Above/Below 50K    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# no null values its good\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code will replace the special character to nan\n",
    "for data in all_data:\n",
    "    for i in data.columns:\n",
    "        data[i].replace(' ?', np.nan, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                0\n",
       "Workclass          0\n",
       "fnlgwt             0\n",
       "Education          0\n",
       "Education Num      0\n",
       "Marital Status     0\n",
       "Occupation         0\n",
       "Relationship       0\n",
       "Race               0\n",
       "Sex                0\n",
       "Capital Gain       0\n",
       "Capital Loss       0\n",
       "Hours/Week         0\n",
       "Country            0\n",
       "Above/Below 50K    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering\n",
    "#Creating targer variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the target variable\n",
    "for data in all_data:\n",
    "    data['target']=data['Above/Below 50K'].apply(lambda x: x.replace('.', ''))\n",
    "    data['target']=data['target'].apply(lambda x: x.strip())\n",
    "    data['target']=data['target'].apply(lambda x: 1 if x=='>50K' else 0)\n",
    "    data.drop(['Above/Below 50K'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24892248524633645"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.sum()/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Education and number of work hour/week looks to be a great variables deciding income. Lets create categories to further enhance its effect. We will create low, medium and high education. I will derive a generic function for creating bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data can be train or test\n",
    "#var name is variable name: should be passed as strings within ('')\n",
    "# bins is list of numeric values like [0,6,10,11]\n",
    "# group names is list of groups you want to create in list form\n",
    "def bin_var(data, var, bins, group_names):\n",
    "    bin_value = bins\n",
    "    group = group_names\n",
    "    data[var+'Cat'] = pd.cut(train[var], bin_value, labels=group)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_var(train, 'Education Num', [0,6,11,16], ['Low', 'Medium', 'High'])\n",
    "bin_var(test, 'Education Num', [0,6,11,16], ['Low', 'Medium', 'High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education NumCat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>2179</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium</th>\n",
       "      <td>15865</td>\n",
       "      <td>3385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>4610</td>\n",
       "      <td>3986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target                0     1\n",
       "Education NumCat             \n",
       "Low                2179   137\n",
       "Medium            15865  3385\n",
       "High               4610  3986"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train['Education NumCat'],train['target'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same way we can bin the Hours/Week variable. Initial exploation suggest that 40 hours is the most fequent value which make sense that it is 8hr/day. Hence we will bin this variable around this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_var(train, 'Hours/Week', [0,35,40,60,100], ['Low', 'Medium', 'High','VeryHigh'])\n",
    "bin_var(test, 'Hours/Week', [0,35,40,60,100], ['Low', 'Medium', 'High','VeryHigh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hours/WeekCat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>5369</td>\n",
       "      <td>505</td>\n",
       "      <td>5874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium</th>\n",
       "      <td>11829</td>\n",
       "      <td>3262</td>\n",
       "      <td>15091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>4796</td>\n",
       "      <td>3349</td>\n",
       "      <td>8145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VeryHigh</th>\n",
       "      <td>660</td>\n",
       "      <td>392</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>22654</td>\n",
       "      <td>7508</td>\n",
       "      <td>30162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target             0     1    All\n",
       "Hours/WeekCat                    \n",
       "Low             5369   505   5874\n",
       "Medium         11829  3262  15091\n",
       "High            4796  3349   8145\n",
       "VeryHigh         660   392   1052\n",
       "All            22654  7508  30162"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train['Hours/WeekCat'],train['target'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying the occupation into Highly Skilled and low Skilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "occu=pd.crosstab(train['Occupation'],train['target'], margins=True).reset_index()\n",
    "def occup(x):\n",
    "    if re.search('managerial', x):\n",
    "        return 'Highskill'\n",
    "    elif re.search('specialty',x):\n",
    "        return 'Highskill'\n",
    "    else:\n",
    "        return 'Lowskill'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Occupa_cat']=train.Occupation.apply(lambda x: x.strip()).apply(lambda x: occup(x))\n",
    "test['Occupa_cat']=test.Occupation.apply(lambda x: x.strip()).apply(lambda x: occup(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same way we can bin the Age variable. The minimum age in train is 17 and max is 90. We can categorize them as young, middle_aged and old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_var(test, 'Age', [17,30,55,100], ['Young', 'Middle_aged', 'Old'])\n",
    "bin_var(train, 'Age', [17,30,55,100], ['Young', 'Middle_aged', 'Old'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marital status can also be binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Marital Status_cat']=train['Marital Status'].apply(lambda x: 'married' if x.startswith('Married',1) else 'Single')\n",
    "test['Marital Status_cat']=test['Marital Status'].apply(lambda x: 'married' if x.startswith('Married',1) else 'Single')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Race has been binned into White and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amer-Indian-Eskimo</th>\n",
       "      <td>252</td>\n",
       "      <td>34</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian-Pac-Islander</th>\n",
       "      <td>647</td>\n",
       "      <td>248</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>2451</td>\n",
       "      <td>366</td>\n",
       "      <td>2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>210</td>\n",
       "      <td>21</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>19094</td>\n",
       "      <td>6839</td>\n",
       "      <td>25933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>22654</td>\n",
       "      <td>7508</td>\n",
       "      <td>30162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target                   0     1    All\n",
       "Race                                   \n",
       " Amer-Indian-Eskimo    252    34    286\n",
       " Asian-Pac-Islander    647   248    895\n",
       " Black                2451   366   2817\n",
       " Other                 210    21    231\n",
       " White               19094  6839  25933\n",
       "All                  22654  7508  30162"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train['Race'],train['target'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Race_cat']=train['Race'].apply(lambda x: x.strip())\n",
    "train['Race_cat']=train['Race_cat'].apply(lambda x: 'White' if x=='White' else 'Other')\n",
    "test['Race_cat']=test['Race'].apply(lambda x: x.strip())\n",
    "test['Race_cat']=test['Race_cat'].apply(lambda x: 'White' if x=='White' else 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work Class is divided into three categories Private, Selfemployed, gov and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workclas(x):\n",
    "    if re.search('Private', x):\n",
    "        return 'Private'\n",
    "    elif re.search('Self', x):\n",
    "        return 'selfempl'\n",
    "    elif re.search('gov', x):\n",
    "        return 'gov'\n",
    "    else:\n",
    "        return 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['WorfClass_cat']=train.Workclass.apply(lambda x: x.strip()).apply(lambda x: workclas(x))\n",
    "test['WorfClass_cat']=test.Workclass.apply(lambda x: x.strip()).apply(lambda x: workclas(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private     22286\n",
       "gov          4289\n",
       "selfempl     3573\n",
       "others         14\n",
       "Name: WorfClass_cat, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['WorfClass_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the target to Y variable\n",
    "Y_tr=train['target']\n",
    "Y_te=test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since target is already assigned I Will drop the target from the train and test along with other unnecessary variables\n",
    "train.drop(['Education','Occupation','Race','Education Num','Age', 'Hours/Week', 'Marital Status','target','fnlgwt','Workclass', 'Capital Gain','Capital Loss', 'Country'], axis=1, inplace=True)\n",
    "test.drop(['Education','Occupation','Race','Education Num','Age', 'Hours/Week', 'Marital Status','Workclass','target','fnlgwt', 'Capital Gain','Capital Loss', 'Country'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list=['WorfClass_cat','Education NumCat', 'AgeCat', 'Race_cat',\n",
    "'Hours/WeekCat',\n",
    " 'Marital Status_cat',\n",
    " 'Occupa_cat',\n",
    " 'Relationship',\n",
    " 'Sex']\n",
    "\n",
    "train_set=pd.get_dummies(train, columns=str_list)\n",
    "test_set=pd.get_dummies(test, columns=str_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection Using Variance Threshold\n",
    "\n",
    "Variance Threshold is a univariate approach to feature selection. It removes all features whose variance doesnt meet some threshold. By default, it removes all zero-variance features, i.e. features that have the same value in all samples. As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples. Boolean features are Bernoulli random variables, and the variance of such variables is given by The below approach removes variable which have more than 80% values are either 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WorfClass_cat_Private', 'WorfClass_cat_gov', 'WorfClass_cat_others',\n",
       "       'WorfClass_cat_selfempl', 'Education NumCat_Low',\n",
       "       'Education NumCat_Medium', 'Education NumCat_High', 'AgeCat_Young',\n",
       "       'AgeCat_Middle_aged', 'AgeCat_Old', 'Race_cat_Other', 'Race_cat_White',\n",
       "       'Hours/WeekCat_Low', 'Hours/WeekCat_Medium', 'Hours/WeekCat_High',\n",
       "       'Hours/WeekCat_VeryHigh', 'Marital Status_cat_Single',\n",
       "       'Marital Status_cat_married', 'Occupa_cat_Highskill',\n",
       "       'Occupa_cat_Lowskill', 'Relationship_ Husband',\n",
       "       'Relationship_ Not-in-family', 'Relationship_ Other-relative',\n",
       "       'Relationship_ Own-child', 'Relationship_ Unmarried',\n",
       "       'Relationship_ Wife', 'Sex_ Female', 'Sex_ Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def variance_threshold_select(df, thresh=0.0, na_replacement=-999):\n",
    "    df1 = df.copy(deep=True) # Make a deep copy of the dataframe\n",
    "    selector = VarianceThreshold(thresh) # passing Threshold\n",
    "    selector.fit(df1.fillna(na_replacement)) # Fill NA values as VarianceThreshold cannot deal with those\n",
    "    df2 = df.loc[:,selector.get_support(indices=False)] # Get new dataframe with columns deleted that have NA values\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=variance_threshold_select(train_set, thresh=.8* (1 - .8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WorfClass_cat_Private', 'Education NumCat_Medium',\n",
      "       'Education NumCat_High', 'AgeCat_Young', 'AgeCat_Middle_aged',\n",
      "       'Hours/WeekCat_Medium', 'Hours/WeekCat_High',\n",
      "       'Marital Status_cat_Single', 'Marital Status_cat_married',\n",
      "       'Occupa_cat_Highskill', 'Occupa_cat_Lowskill', 'Relationship_ Husband',\n",
      "       'Relationship_ Not-in-family', 'Sex_ Female', 'Sex_ Male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below the number of columns have been reduced to 15 because of the the variance threshold. The removed columns have the same value in 80% of the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_tr=df2.columns # creates list of columns\n",
    "col_te=test_set.columns # creates list of columns for test\n",
    "X_tr=df2.values # creates array of values of features\n",
    "X_te=test_set[col_tr].values#subseting the test dataset to get the same variable as train and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "#    else:\n",
    "#        print('Confusion matrix, without normalization')\n",
    "\n",
    "#    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "def show_data(cm, print_res = 0):\n",
    "    tp = cm[1,1]\n",
    "    fn = cm[1,0]\n",
    "    fp = cm[0,1]\n",
    "    tn = cm[0,0]\n",
    "    if print_res == 1:\n",
    "        print('Precision =     {:.3f}'.format(tp/(tp+fp)))\n",
    "        print('Recall (TPR) =  {:.3f}'.format(tp/(tp+fn)))\n",
    "        print('Fallout (FPR) = {:.3e}'.format(fp/(fp+tn)))\n",
    "    return tp/(tp+fp), tp/(tp+fn), fp/(fp+tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =     0.444\n",
      "Recall (TPR) =  0.863\n",
      "Fallout (FPR) = 3.513e-01\n"
     ]
    }
   ],
   "source": [
    "lrn = LogisticRegression(penalty = 'l1', C = .001, class_weight='balanced')\n",
    "\n",
    "lrn.fit(X_tr, Y_tr)\n",
    "y_pred = lrn.predict(X_te)\n",
    "cm = confusion_matrix(Y_te, y_pred)\n",
    "if lrn.classes_[0] == 1:\n",
    "    cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "plot_confusion_matrix(cm, ['0', '1'], )\n",
    "pr, tpr, fpr = show_data(cm, print_res = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.701261620185923\n",
      "F1 score: 0.5866029587429936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "    \n",
    "print ('Accuracy:', accuracy_score(Y_te, y_pred))\n",
    "print ('F1 score:', f1_score(Y_te,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding Important features for High and Low Paying Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "0   0.000000\n",
      "1   0.000000\n",
      "2   0.560646\n",
      "3  -0.275337\n",
      "4   0.001473\n",
      "5   0.000000\n",
      "6   0.078815\n",
      "7  -0.967225\n",
      "8   0.549511\n",
      "9   0.102070\n",
      "10 -0.262941\n",
      "11  0.000000\n",
      "12  0.000000\n",
      "13  0.000000\n",
      "14  0.000000\n",
      "                      0                        1                      2   \\\n",
      "0  WorfClass_cat_Private  Education NumCat_Medium  Education NumCat_High   \n",
      "\n",
      "             3                   4                     5                   6   \\\n",
      "0  AgeCat_Young  AgeCat_Middle_aged  Hours/WeekCat_Medium  Hours/WeekCat_High   \n",
      "\n",
      "                          7                           8   \\\n",
      "0  Marital Status_cat_Single  Marital Status_cat_married   \n",
      "\n",
      "                     9                    10                     11  \\\n",
      "0  Occupa_cat_Highskill  Occupa_cat_Lowskill  Relationship_ Husband   \n",
      "\n",
      "                            12           13         14  \n",
      "0  Relationship_ Not-in-family  Sex_ Female  Sex_ Male  \n"
     ]
    }
   ],
   "source": [
    "# Understanding the coefficients\n",
    "coff=pd.DataFrame(lrn.coef_).T \n",
    "col=pd.DataFrame(col_tr).T \n",
    "print(coff)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above positive coefficients are for high paying and neagtive for low paying.As you can see High number of years of education, high workhour/week are importand for getting high salary and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(6, 'WorfClass_cat_Private'),\n",
       " (5, 'Education NumCat_Medium'),\n",
       " (1, 'Education NumCat_High'),\n",
       " (1, 'AgeCat_Young'),\n",
       " (1, 'AgeCat_Middle_aged'),\n",
       " (4, 'Hours/WeekCat_Medium'),\n",
       " (1, 'Hours/WeekCat_High'),\n",
       " (1, 'Marital Status_cat_Single'),\n",
       " (1, 'Marital Status_cat_married'),\n",
       " (1, 'Occupa_cat_Highskill'),\n",
       " (2, 'Occupa_cat_Lowskill'),\n",
       " (3, 'Relationship_ Husband'),\n",
       " (1, 'Relationship_ Not-in-family'),\n",
       " (1, 'Sex_ Female'),\n",
       " (1, 'Sex_ Male')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE, f_regression\n",
    "#stop the search when only the last feature is left\n",
    "rfe = RFE(lrn, n_features_to_select=10, verbose =3 )\n",
    "rfe.fit(X_tr,Y_tr)\n",
    "list(zip(map(lambda x: round(x, 4), rfe.ranking_), col_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
